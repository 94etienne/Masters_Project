{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":68479,"databundleVersionId":7609535,"sourceType":"competition"},{"sourceId":7009925,"sourceType":"datasetVersion","datasetId":4030196},{"sourceId":7678967,"sourceType":"datasetVersion","datasetId":4398482}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# pip install -q pytorch-tabnet","metadata":{"execution":{"iopub.status.busy":"2024-02-23T12:23:48.839806Z","iopub.execute_input":"2024-02-23T12:23:48.840179Z","iopub.status.idle":"2024-02-23T12:23:48.869783Z","shell.execute_reply.started":"2024-02-23T12:23:48.840147Z","shell.execute_reply":"2024-02-23T12:23:48.868823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nimport random\nimport numpy as np \nimport pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.model_selection import KFold, GroupKFold, StratifiedKFold\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import f1_score, accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom lightgbm import LGBMClassifier, early_stopping\nfrom catboost import CatBoostClassifier\n# from pytorch_tabnet.tab_model import TabNetClassifier\nimport optuna\nimport pickle\nimport gc\nimport math\nfrom functools import partial","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-23T12:47:57.485903Z","iopub.execute_input":"2024-02-23T12:47:57.486280Z","iopub.status.idle":"2024-02-23T12:47:57.493865Z","shell.execute_reply.started":"2024-02-23T12:47:57.486251Z","shell.execute_reply":"2024-02-23T12:47:57.493037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed = 42):\n    \"\"\"\n    Setting seed value to ensure reproducibility across runs\n    \"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    \n\ndef class2dict(f):\n    \"\"\"\n    Convert a class to a dictionary\n    \"\"\"\n    return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))","metadata":{"execution":{"iopub.status.busy":"2024-02-23T12:47:57.609902Z","iopub.execute_input":"2024-02-23T12:47:57.610363Z","iopub.status.idle":"2024-02-23T12:47:57.617107Z","shell.execute_reply.started":"2024-02-23T12:47:57.610334Z","shell.execute_reply":"2024-02-23T12:47:57.615353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Arguments as follow:\n1. model (str) = Choice of model being trained here. Models being used right now: 'randomforest', 'lightgbm', 'xgboost', 'catboost'\n2. n_trials (int) = Hyperparameter optimization is done using Optuna. n_trials set the number of optimization runs performed \n3. additional_data (boolean) = Whether to use the additional data from https://www.kaggle.com/datasets/aravindpcoder/obesity-or-cvd-risk-classifyregressorcluster\n4. metric (str) = Denote the metric Optuna should use to tune the hyperparameters. Accept either 'accuracy' or 'f1'\n5. wandb (boolean) = Whether to use wandb to track experiment runs\n6. seed (int) = Seed value\n7. target (str) = Target column for this dataset. Do not change.\n8. folds (int) = Number of k-folds cross validation","metadata":{}},{"cell_type":"code","source":"class args:\n    model = 'lightgbm'\n    n_trials = 175   #Catboost = 15, lightgbm = 200, xgboost = 70, randomforest = 150, tabnet = 5\n    additional_data = True \n    metric = 'accuracy' #f1 or accuracy\n    wandb = True\n    standardize = True\n    seed = 42\n    target = 'NObeyesdad' #Do not change\n    folds = 15\n    \n    \ntarget_to_label = {'Overweight_Level_II': 0, 'Normal_Weight': 1, 'Insufficient_Weight': 2, 'Obesity_Type_III': 3, 'Obesity_Type_II': 4, 'Overweight_Level_I': 5, 'Obesity_Type_I': 6}\nlabel_to_target = {label:target for target,label in target_to_label.items()}","metadata":{"execution":{"iopub.status.busy":"2024-02-23T12:50:15.563386Z","iopub.execute_input":"2024-02-23T12:50:15.563724Z","iopub.status.idle":"2024-02-23T12:50:15.569472Z","shell.execute_reply.started":"2024-02-23T12:50:15.563698Z","shell.execute_reply":"2024-02-23T12:50:15.568496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if args.wandb:\n    # Experiement tracking using Weight and Biases\n    import wandb\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n    wandb.login(key=secret_value_0)\n    run = wandb.init(project='playground_s4e2', config=class2dict(args), group=args.model)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T12:50:15.704768Z","iopub.execute_input":"2024-02-23T12:50:15.705148Z","iopub.status.idle":"2024-02-23T12:50:15.709477Z","shell.execute_reply.started":"2024-02-23T12:50:15.705122Z","shell.execute_reply":"2024-02-23T12:50:15.708726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/playground-series-s4e2/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s4e2/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-02-23T12:50:16.002436Z","iopub.execute_input":"2024-02-23T12:50:16.002820Z","iopub.status.idle":"2024-02-23T12:50:16.074923Z","shell.execute_reply.started":"2024-02-23T12:50:16.002791Z","shell.execute_reply":"2024-02-23T12:50:16.073850Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Features:\n1. Gender (Male/Female)\n2. Age (Continuous Variable)\n3. Height (Continuous Variable)\n4. family_history_with_overweight (yes/no)\n5. FAVC - Frequent consumption of high caloric food (yes/no)\n6. FCVC - Frequency of consumption of vegetables (Continuous Variable)\n7. NCP - Number of main meals (Continuous Variable)\n8. CAEC - Consumption of food between meals (no/Sometimes/Frequently/Always)\n9. SMOKE (yes/no)\n10. CH2O - Consumption of water daily (Continuous Variable)\n11. SCC - Calories consumption monitoring (no/yes)\n12. FAF - Physical activity frequency (Continuous Variable)\n13. TUE - Time using technology devices (Continuous Variable)\n14. CALC - Consumption of alcohol (no/Sometimes/Frequently/Always)\n15. MTRANS - Transportation used (Public_Transportation/Automobile/Walking/Motorbike/Bike)\n16. NObeyesdad - Target (Overweight_Level_II/Normal_Weight/Insufficient_Weight/Obesity_Type_III/Obesity_Type_II/Overweight_Level_I/Obesity_Type_I)","metadata":{}},{"cell_type":"markdown","source":"I took the feature engineering code from this notebook: https://www.kaggle.com/code/ravi20076/playgrounds4e02-eda-baseline","metadata":{}},{"cell_type":"code","source":"def feature_engineering(_df, training):\n    \"\"\"\n    \n    Perform feature training by encoding categorical columns, binning continuous variable\n    \"\"\"\n    _df = pd.get_dummies(_df, columns=['MTRANS'])\n    _df[['MTRANS_Automobile', 'MTRANS_Bike', 'MTRANS_Motorbike','MTRANS_Public_Transportation', 'MTRANS_Walking']] = _df[['MTRANS_Automobile', 'MTRANS_Bike', 'MTRANS_Motorbike','MTRANS_Public_Transportation', 'MTRANS_Walking']].astype(np.int8)\n    _df[\"Gender\"] = np.where(_df[\"Gender\"] == \"Male\", 1,0).astype(np.uint8)\n    _df[\"family_history_with_overweight\"] = np.where(_df[\"family_history_with_overweight\"] == \"yes\", 1,0).astype(np.uint8)\n    _df['SMOKE'] = np.where(_df[\"SMOKE\"] == \"yes\", 1,0).astype(np.uint8)\n    _df['FAVC'] = np.where(_df[\"FAVC\"] == \"no\", 1,0).astype(np.uint8)\n    _df[\"CAEC\"] = _df[\"CAEC\"].map({\"no\": 0, \"Sometimes\": 1, \"Frequently\": 2, \"Always\": 3}).astype(np.uint8)\n    _df['SCC']  = np.where(_df[\"SCC\"] == \"no\", 1,0).astype(np.uint8)\n    _df[\"CALC\"] = _df[\"CALC\"].map({\"no\": 0, \"Sometimes\": 1, \"Frequently\": 2, \"Always\": 2}).astype(np.uint8)\n    _df[\"BMI\"] = _df[\"Weight\"] / _df[\"Height\"]**2\n    _df[\"BMI_Grp\"] = np.select([_df[\"BMI\"] < 18.5, _df[\"BMI\"] < 25, _df[\"BMI\"] < 30, _df[\"BMI\"] < 35, _df[\"BMI\"] < 40], [0,1,2,3,4], 5).astype(np.int8)\n    \n#     _df[\"BMIbyNCP\"]  = np.log1p(_df[\"BMI\"]) - np.log1p(_df[\"NCP\"])\n#     _df[\"BMIFAF\"]    = (_df[\"BMI\"] * _df[\"FAF\"])/ 25.0\n#     _df[\"FAFmTUE\"]   = _df[\"FAF\"] - _df[\"TUE\"]\n#     _df[\"FCVCpNCP\"]  = _df['FCVC'] * _df['NCP']\n#     _df['TechUse']   = np.log1p(_df['TUE']) - np.log1p(_df['Age'])\n    \n    if training:\n        _df['NObeyesdad'] = _df['NObeyesdad'].map(target_to_label)\n    \n    return _df","metadata":{"execution":{"iopub.status.busy":"2024-02-23T12:50:16.460782Z","iopub.execute_input":"2024-02-23T12:50:16.461182Z","iopub.status.idle":"2024-02-23T12:50:16.472059Z","shell.execute_reply.started":"2024-02-23T12:50:16.461155Z","shell.execute_reply":"2024-02-23T12:50:16.470999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = feature_engineering(train, True)\nif args.additional_data:\n    # If true. use the additional dataset for training. https://www.kaggle.com/datasets/aravindpcoder/obesity-or-cvd-risk-classifyregressorcluster\n    add_data = pd.read_csv('/kaggle/input/obesity-or-cvd-risk-classifyregressorcluster/ObesityDataSet.csv')\n    add_data = feature_engineering(add_data, True)\n\nif args.standardize:\n    features = [i for i in df.columns if i != 'id' and i != args.target]\n    df_id = df['id'].values\n    df_target = df[args.target].values\n    \n    scaler = StandardScaler().fit(df.loc[:, features])\n    df = scaler.transform(df.loc[:, features])\n    df = pd.DataFrame(df, columns=features)\n    df['id'] = df_id\n    df[args.target] = df_target\n    \n    if args.additional_data:\n        add_data_target = add_data[args.target].values\n        add_data = scaler.transform(add_data.loc[:, features])\n        add_data = pd.DataFrame(add_data, columns=features)\n        add_data[args.target] = add_data_target","metadata":{"execution":{"iopub.status.busy":"2024-02-23T12:50:16.789705Z","iopub.execute_input":"2024-02-23T12:50:16.790039Z","iopub.status.idle":"2024-02-23T12:50:16.863211Z","shell.execute_reply.started":"2024-02-23T12:50:16.790001Z","shell.execute_reply":"2024-02-23T12:50:16.862231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modelling","metadata":{}},{"cell_type":"code","source":"# Define the objective metric used to perform hyperparameter tuning. Note that the competition uses accuracy as metric, but \n# we can tune the model based on other metrics to allow more variation of models\n\nif args.metric == 'f1':\n    objective_metric = partial(f1_score, average='micro') \nelif args.metric == 'accuracy':\n    objective_metric = accuracy_score\nelse:\n    print('Objective Metric not defined')","metadata":{"execution":{"iopub.status.busy":"2024-02-23T12:50:17.506554Z","iopub.execute_input":"2024-02-23T12:50:17.506948Z","iopub.status.idle":"2024-02-23T12:50:17.511778Z","shell.execute_reply.started":"2024-02-23T12:50:17.506921Z","shell.execute_reply":"2024-02-23T12:50:17.510632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nThis is the objective function Optuna uses to perform hyperparameter tuning. In each trial/run, Optuna selects a value from the range\ngiven (defined within trial.suggest_int or trial_suggest_float), train a model, and find out the peformance on the validation dataset.\nBased on the current performance and the performance from past trials, Optuna automatically adjusts the hyperparmeter setting and try\nto converge to an optimal value within least iteration.\n\n\"\"\"\n\ndef objective(trial, model_name, X_train, y_train, X_val, y_val):\n    if model_name == 'lightgbm':\n        lightgbm_params = {\n            'max_depth': trial.suggest_int('max_depth', 3, 12),\n            'num_leaves': trial.suggest_int('num_leaves', 30, 200),\n            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 50, 600),\n            'n_estimators': trial.suggest_int('n_estimators', 5, 100),\n            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n            'min_split_gain': trial.suggest_float('min_split_gain', 0.0, 10),\n            'reg_alpha' : trial.suggest_float('reg_alpha', 0.0, 50),\n            'reg_lambda' : trial.suggest_float('reg_lambda', 0.0, 40),\n            'verbose': -1\n        }\n        model = LGBMClassifier(**lightgbm_params)\n        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=[early_stopping(50, verbose=False)])\n            \n    elif model_name == 'xgboost':\n        xgboost_params = {\n            'eta': trial.suggest_float('eta', 0.02, 0.3),\n            'subsample': trial.suggest_float('subsample', 0.6, 0.9),\n            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 0.8),\n            'max_depth': trial.suggest_int('max_depth', 3, 15),\n            'lambda': trial.suggest_int('lambda', 1, 10),\n            'early_stopping_rounds': 50,\n        }\n        model = XGBClassifier(**xgboost_params)\n        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=0)\n\n    elif model_name == 'catboost':\n        catboost_params = {\n            'learning_rate': trial.suggest_float('learning_rate', 0.03, 0.2),\n            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 3, 30),\n            'depth': trial.suggest_int('depth', 4, 10),\n            'rsm' : trial.suggest_float('rsm', 0.5, 1.0),\n            'verbose' : 0,\n        }\n\n        model = CatBoostClassifier(**catboost_params)\n        model.fit(X_train, y_train)\n    \n    elif model_name == 'randomforest':\n        randomforest_params = {\n            'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n            'max_depth': trial.suggest_int('max_depth', 4, 40),\n            'min_samples_split': trial.suggest_int('min_samples_split', 10, 300),\n        }\n        model = RandomForestClassifier(**randomforest_params)\n        model.fit(X_train, y_train)\n        \n    elif model_name == 'tabnet':\n        tabnet_params = {\n            'n_d': trial.suggest_int('n_d', 8, 16),\n            'n_steps': trial.suggest_int('n_steps', 3, 5)\n        }\n        tabnet_params['n_a'] = tabnet_params['n_d']\n        model = TabNetClassifier(**tabnet_params)\n        model.fit(X_train.values, y_train.values, eval_set=[(X_val.values, y_val.values)])\n        \n    elif model_name == 'adaboost':\n        adaboost_params = {\n            'n_estimators': trial.suggest_int('n_estimators', 30, 100),\n            'learning_rate' : trial.suggest_float('learning_rate', 0.1, 1.5),\n        }\n        model = AdaBoostClassifier(**adaboost_params)\n        model.fit(X_train.values, y_train.values)\n\n\n    preds = model.predict(X_val.values)\n    metric = objective_metric(y_val, preds)\n    return metric","metadata":{"execution":{"iopub.status.busy":"2024-02-23T12:50:17.698846Z","iopub.execute_input":"2024-02-23T12:50:17.699272Z","iopub.status.idle":"2024-02-23T12:50:17.713942Z","shell.execute_reply.started":"2024-02-23T12:50:17.699237Z","shell.execute_reply":"2024-02-23T12:50:17.712784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_single_fold(fold, model_name, train_idx, val_idx):\n    features = [i for i in df.columns if i != 'id' and i != args.target]\n   \n    X_train = df.loc[train_idx, features]\n    y_train = df.loc[train_idx, args.target]\n    X_val = df.loc[val_idx, features]\n    y_val = df.loc[val_idx, args.target]\n    \n    if args.additional_data:\n        # Concatenate the original data with the additional data. Note that the additional data is used on train only and not \n        # validation. The additional data may be of a different distribution so we should not use it to validate our model. \n        X_train = pd.concat((X_train, add_data[features]))\n        y_train = pd.concat((y_train, add_data[args.target]))\n    \n    # Begin hyperparameter tuning to find out the best choice of hyperparameters\n    f = partial(objective, model_name=model_name, X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val)\n    study = optuna.create_study(direction='maximize')\n    study.optimize(f, n_trials=args.n_trials)\n    model_params = study.best_trial.params\n    print('Best trial:', model_params)\n\n    # Once the optimal hyperparameters are obtained, we used it to fit the model \n    if model_name == 'lightgbm':\n        model_params['verbose'] = -1\n        best_model = LGBMClassifier(**model_params)\n        best_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=[early_stopping(50, verbose=False)])\n        \n    elif model_name == 'xgboost':\n        model_params['early_stopping_rounds'] = 50\n        best_model = XGBClassifier(**model_params)\n        best_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=0)\n        \n    elif model_name == 'catboost':\n        model_params['verbose'] = 0\n        best_model = CatBoostClassifier(**model_params)\n        best_model.fit(X_train, y_train)\n    \n    elif model_name == 'randomforest':\n        best_model = RandomForestClassifier(**model_params)\n        best_model.fit(X_train, y_train)\n    \n    elif model_name == 'tabnet':\n        best_model = TabNetClassifier(**model_params)\n        best_model.fit(X_train.values, y_train.values, eval_set=[(X_val.values, y_val.values)])\n        \n    elif model_name == 'adaboost':\n        best_model = AdaBoostClassifier(**model_params)\n        best_model.fit(X_train.values, y_train.values)\n    \n    preds = best_model.predict(X_val.values)\n\n   # Evaluating the best model performance\n    score = accuracy_score(y_val, preds)\n    print(f\"Best {args.model} at fold {fold} has accuracy = {score:.4f}\")\n    \n    if args.wandb:\n        wandb.log({f\"Fold_{fold}\": score})\n    \n    # Saving Out of fold\n    probs = best_model.predict_proba(X_val.values)\n    _oof = pd.DataFrame(probs)\n    _oof['id'] = df.loc[val_idx, 'id'].values\n    _oof['preds'] = preds\n    _oof['ground_truth'] = df.loc[val_idx, 'NObeyesdad'].values\n    \n    # Saving the best model\n    pickle.dump(best_model, open(f\"{model_name}_fold{fold}\", \"wb\"))\n   \n        \n    del best_model\n    gc.collect()\n    \n    \n    return _oof","metadata":{"execution":{"iopub.status.busy":"2024-02-23T12:50:17.865178Z","iopub.execute_input":"2024-02-23T12:50:17.865527Z","iopub.status.idle":"2024-02-23T12:50:17.881241Z","shell.execute_reply.started":"2024-02-23T12:50:17.865500Z","shell.execute_reply":"2024-02-23T12:50:17.880242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=args.folds)\noof = []\nfor i, (train_idx, val_idx) in enumerate(skf.split(df.drop(columns=args.target), df[args.target])):\n    _oof = run_single_fold(i, args.model, train_idx, val_idx)\n    oof.append(_oof)\n    \noof = pd.concat(oof, axis=0)\noof.to_csv(f\"oof_{args.model}.csv\", index=False)\n\ncv_score = accuracy_score(oof['ground_truth'], oof['preds'])\nprint(f\"Overall CV score = {cv_score}\")\nif args.wandb:\n    wandb.log({\"CV\": cv_score})","metadata":{"execution":{"iopub.status.busy":"2024-02-23T12:50:18.244901Z","iopub.execute_input":"2024-02-23T12:50:18.245268Z","iopub.status.idle":"2024-02-23T12:50:25.816470Z","shell.execute_reply.started":"2024-02-23T12:50:18.245241Z","shell.execute_reply":"2024-02-23T12:50:25.815337Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"test_ids = test['id'].values\ntest = test.drop(columns='id')\ntest = feature_engineering(test, training=False)\n\nif args.standardize:\n    test = scaler.transform(test)","metadata":{"execution":{"iopub.status.busy":"2024-02-12T14:25:45.769854Z","iopub.execute_input":"2024-02-12T14:25:45.770802Z","iopub.status.idle":"2024-02-12T14:25:45.823426Z","shell.execute_reply.started":"2024-02-12T14:25:45.770751Z","shell.execute_reply":"2024-02-12T14:25:45.822632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = {i: None for i in range(args.folds)}\nfor fold in results.keys():\n    with open(f\"/kaggle/working/{args.model}_fold{fold}\", 'rb') as f:\n        model = pickle.load(f)\n    probs = model.predict_proba(test)\n    results[fold] = probs\n    \ntest_probs = np.mean(np.stack(list(results.values())), axis=0)\npredictions = np.argmax(test_probs, axis=1)\n\ntest_probs = pd.DataFrame(test_probs)\ntest_probs['id'] = test_ids\ntest_probs.to_csv(f\"test_probs_{args.model}.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-12T14:25:48.836381Z","iopub.execute_input":"2024-02-12T14:25:48.836768Z","iopub.status.idle":"2024-02-12T14:25:54.364688Z","shell.execute_reply.started":"2024-02-12T14:25:48.836739Z","shell.execute_reply":"2024-02-12T14:25:54.363798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'id': test_ids, args.target: predictions})\nsubmission[args.target] = submission[args.target].map(label_to_target)\nsubmission.to_csv('submission.csv', index=False)\n\nif args.wandb:\n    wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-02-12T14:25:57.165493Z","iopub.execute_input":"2024-02-12T14:25:57.166418Z","iopub.status.idle":"2024-02-12T14:25:57.200556Z","shell.execute_reply.started":"2024-02-12T14:25:57.166384Z","shell.execute_reply":"2024-02-12T14:25:57.199764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}